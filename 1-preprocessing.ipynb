{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Imports***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Loading Dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('imdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Creating DataFrames***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.DataFrame(ds['train'])\n",
    "test_set = pd.DataFrame(ds['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2  If only to avoid making this type of film in t...      0\n",
       "3  This film was probably inspired by Godard's Ma...      0\n",
       "4  Oh, brother...after hearing about this ridicul...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exploring Dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "# shape of data\n",
    "print(train_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     object\n",
       "label     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    12500\n",
       "1    12500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights:** There is `25000` rows of text in both the training data and the test data. There are only 2 features, `label` that labels the data with either `0` for negative and `1` for positive and `text` which is a long string of text. There are both even amounts of data for each label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Checking for Nulls***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_set.isnull().sum())\n",
    "print(test_set.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights:** There is no null data. So we can continue on with the preprocessing and tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Removing Punctuation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text): # Removes punctuation from text\n",
    "    text = text.lower()\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyz '\n",
    "    text = \"\".join([char for char in text if char in alphabet])\n",
    "    return text\n",
    "\n",
    "# applying function to data\n",
    "train_set['text_processed'] = train_set['text'].apply(lambda x: remove_punctuation(x))\n",
    "test_set['text_processed'] = test_set['text'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tokenization***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text): #  tokenizes the text\n",
    "    tokens = text.split(\" \")\n",
    "    tokens = ([word for word in tokens if word not in '']) # removing empty spaces\n",
    "    return tokens\n",
    "\n",
    "# applying function to data\n",
    "train_set['text_processed'] = train_set['text_processed'].apply(lambda x: tokenize(x))\n",
    "test_set['text_processed'] = test_set['text_processed'].apply(lambda x: tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "2460\n",
      "231.74028\n"
     ]
    }
   ],
   "source": [
    "# exploring new tokenized data\n",
    "print(train_set['text_processed'].apply(lambda x: len(x)).min())\n",
    "print(train_set['text_processed'].apply(lambda x: len(x)).max())\n",
    "print(train_set['text_processed'].apply(lambda x: len(x)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights:** After the tokenizer we can see that the max amount of words is `2460` and minimum is `10`. The mean is `231.7403` showing that there may be outlier data that has significantly more words than the majority of the data. We will be keeping these outliers so the model can be able to read large tex as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Stop Word Removal***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')\n",
    "\n",
    "def stop_words(text): # removes common words \n",
    "    text = [word for word in text if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "# applying function to data\n",
    "train_set['text_processed'] = train_set['text_processed'].apply(lambda x: stop_words(x))\n",
    "test_set['text_processed'] = test_set['text_processed'].apply(lambda x: stop_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1440\n",
      "122.9484\n"
     ]
    }
   ],
   "source": [
    "# exploring new data after stop word removal\n",
    "print(train_set['text_processed'].apply(lambda x: len(x)).min())\n",
    "print(train_set['text_processed'].apply(lambda x: len(x)).max())\n",
    "print(train_set['text_processed'].apply(lambda x: len(x)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights:** After removing the stop words the maximum has decreased to `1440` words along with the min decreasing to `4` words. The mean also decreased to `122.9484` words. This is a significant decrease in the range of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Finished Preprocessed Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>[rented, curiousyellow, video, store, controve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "      <td>[curious, yellow, risible, pretentious, steami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[avoid, making, type, film, future, film, inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>[film, probably, inspired, godards, masculin, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "      <td>[oh, brotherafter, hearing, ridiculous, film, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0   \n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0   \n",
       "2  If only to avoid making this type of film in t...      0   \n",
       "3  This film was probably inspired by Godard's Ma...      0   \n",
       "4  Oh, brother...after hearing about this ridicul...      0   \n",
       "\n",
       "                                      text_processed  \n",
       "0  [rented, curiousyellow, video, store, controve...  \n",
       "1  [curious, yellow, risible, pretentious, steami...  \n",
       "2  [avoid, making, type, film, future, film, inte...  \n",
       "3  [film, probably, inspired, godards, masculin, ...  \n",
       "4  [oh, brotherafter, hearing, ridiculous, film, ...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Saving Data as CSV's***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_csv('../data/train_set.csv', index=False)\n",
    "test_set.to_csv('../data/test_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to github issues I could not save the data into folders like usual. Although the code is here and easy to run to create the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
